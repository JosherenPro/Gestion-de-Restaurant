"""
Service de Chat IA utilisant Cerebras API avec Llama 3.3-70B
"""
import os
from typing import Optional, List
from cerebras.cloud.sdk import Cerebras

# Configuration du client Cerebras
def get_cerebras_client():
    api_key = os.environ.get("CEREBRAS_API_KEY")
    if not api_key:
        return None
    return Cerebras(api_key=api_key)


def format_plats_context(plats: List[dict]) -> str:
    """Formate la liste des plats pour le contexte de l'IA"""
    context_lines = []
    for plat in plats:
        line = f"- {plat['nom']}: {plat.get('description', 'Pas de description')}"
        if plat.get('prix'):
            line += f" | Prix: {plat['prix']} FCFA"
        if plat.get('categorie'):
            line += f" | Cat√©gorie: {plat['categorie']}"
        if not plat.get('disponible', True):
            line += " | ‚ö†Ô∏è INDISPONIBLE"
        context_lines.append(line)
    return "\n".join(context_lines)


SYSTEM_PROMPT = """Tu es l'assistant virtuel du restaurant RestoDeluxe, un restaurant gastronomique offrant une cuisine de qualit√©. Tu r√©ponds aux questions des clients sur les plats du menu de mani√®re amicale, professionnelle et chaleureuse.

üìã MENU ACTUEL DU RESTAURANT:
{menu_context}

üéØ R√àGLES √Ä SUIVRE:
1. R√©ponds TOUJOURS en fran√ßais
2. Sois concis mais informatif (max 2-3 phrases par r√©ponse)
3. Utilise des emojis pour rendre tes r√©ponses plus chaleureuses üçΩÔ∏è
4. Si on te demande des allerg√®nes ou ingr√©dients que tu ne connais pas, dis-le honn√™tement
5. Sugg√®re des plats similaires quand c'est pertinent
6. Si le client h√©site, recommande tes favoris du menu
7. Reste dans le contexte du restaurant - ne r√©ponds pas aux questions hors sujet
8. Si un plat est indisponible, propose une alternative

üí° EXEMPLES DE R√âPONSES:
- "Le Poulet grill√© est accompagn√© de l√©gumes de saison üçó C'est l'un de nos best-sellers!"
- "Je vous recommande notre Atti√©k√©, c'est un d√©lice traditionnel ivoirien üá®üáÆ"
- "Ce plat ne contient pas de gluten, vous pouvez le d√©guster en toute tranquillit√© ‚ú®"
"""


async def get_ai_response(
    question: str, 
    plats: List[dict], 
    conversation_history: Optional[List[dict]] = None
) -> dict:
    """
    Obtient une r√©ponse de l'IA Cerebras pour une question sur les plats
    
    Args:
        question: La question du client
        plats: Liste des plats du menu
        conversation_history: Historique de conversation optionnel
        
    Returns:
        dict avec 'response' et 'success'
    """
    client = get_cerebras_client()
    
    if not client:
        # Fallback si pas de cl√© API
        return {
            "success": False,
            "response": "üîß Le service de chat IA n'est pas configur√©. Veuillez contacter le restaurant directement pour vos questions.",
            "error": "API_KEY_MISSING"
        }
    
    try:
        # Formater le contexte du menu
        menu_context = format_plats_context(plats)
        system_prompt = SYSTEM_PROMPT.format(menu_context=menu_context)
        
        # Construire les messages
        messages = [{"role": "system", "content": system_prompt}]
        
        # Ajouter l'historique de conversation si pr√©sent
        if conversation_history:
            for msg in conversation_history[-6:]:  # Limiter √† 6 derniers messages
                messages.append(msg)
        
        # Ajouter la question actuelle
        messages.append({"role": "user", "content": question})
        
        # Appeler Cerebras API
        completion = client.chat.completions.create(
            messages=messages,
            model="llama-3.3-70b",
            max_completion_tokens=256,
            temperature=0.7,
            top_p=0.9,
            stream=False
        )
        
        ai_response = completion.choices[0].message.content
        
        return {
            "success": True,
            "response": ai_response,
            "model": "llama-3.3-70b"
        }
        
    except Exception as e:
        print(f"Erreur Cerebras API: {str(e)}")
        return {
            "success": False,
            "response": "üòî D√©sol√©, je rencontre un probl√®me technique. N'h√©sitez pas √† demander √† notre √©quipe!",
            "error": str(e)
        }


# R√©ponses de fallback pour les questions courantes (si API indisponible)
FALLBACK_RESPONSES = {
    "allergene": "Pour les informations sur les allerg√®nes, veuillez consulter notre √©quipe en salle qui pourra vous renseigner pr√©cis√©ment.",
    "vegetarien": "Nous proposons plusieurs options v√©g√©tariennes. Regardez notre carte ou demandez conseil √† nos serveurs!",
    "recommandation": "Je vous recommande nos plats signature! N'h√©sitez pas √† demander les suggestions du chef √† notre √©quipe.",
    "default": "Pour plus d'informations, notre √©quipe se fera un plaisir de vous aider!"
}


def get_fallback_response(question: str) -> str:
    """Retourne une r√©ponse de fallback bas√©e sur des mots-cl√©s"""
    question_lower = question.lower()
    
    if any(word in question_lower for word in ["allerg√®ne", "allergie", "allergique", "gluten", "lactose"]):
        return FALLBACK_RESPONSES["allergene"]
    elif any(word in question_lower for word in ["v√©g√©tarien", "vegetarien", "vegan", "l√©gume"]):
        return FALLBACK_RESPONSES["vegetarien"]
    elif any(word in question_lower for word in ["recommande", "conseil", "sugg√®re", "meilleur", "populaire"]):
        return FALLBACK_RESPONSES["recommandation"]
    
    return FALLBACK_RESPONSES["default"]
